# Distributed Financial Processing

## ğŸ—ï¸ Projet : SystÃ¨mes DistribuÃ©s pour le Traitement des DonnÃ©es

### ğŸ“Œ PrÃ©sentation
Ce projet a Ã©tÃ© rÃ©alisÃ© par une Ã©quipe de **6 Ã©tudiants**, rÃ©partis en **3 groupes de 2** :
- **DÃ©veloppement logiciel et infrastructure**
- **Cluster Kubernetes et gestion du dÃ©ploiement**
- **Site Reliability Engineering (SRE)**

ğŸš€ **Ce dÃ©pÃ´t concerne la partie dÃ©veloppement logiciel**, qui inclut la conception de lâ€™architecture logicielle, lâ€™implÃ©mentation des microservices et leur intÃ©gration avec Kafka et PostgreSQL.  
ğŸš€ **Il inclut Ã©galement les services Kubernetes et le dÃ©ploiement des applications**.

ğŸ’¡ **Lâ€™architecture de ce projet a Ã©tÃ© pensÃ©e et rÃ©alisÃ©e par [FelinaeBlanc](https://github.com/FelinaeBlanc) sur GitHub. Une autre personne a contribuÃ© Ã  sa mise en Å“uvre, mais jâ€™ai Ã©tÃ© lâ€™architecte principal.**

Nous avons conÃ§u un **systÃ¨me distribuÃ©** permettant le **traitement et lâ€™analyse de donnÃ©es financiÃ¨res**. Il dÃ©montre la capacitÃ© dâ€™une architecture distribuÃ©e Ã  traiter de **grandes quantitÃ©s dâ€™informations** avec **scalabilitÃ©** et **rÃ©silience**.

---

## ğŸ¯ Objectif Principal
Mettre en Å“uvre un **systÃ¨me distribuÃ©** capable dâ€™analyser et de traiter efficacement des **donnÃ©es financiÃ¨res**.

### ğŸ”¹ Ã‰tapes Principales
1. **RÃ©cupÃ©ration des donnÃ©es brutes**  
   ğŸ“Œ Collecte des valeurs dâ€™un grand nombre dâ€™actions (*symboles*) depuis diverses sources.

2. **Traitement des donnÃ©es**  
   ğŸ“Œ Analyse des donnÃ©es pour calculer des indicateurs techniques tels que le **RSI (Relative Strength Index)** et dâ€™autres mÃ©triques financiÃ¨res.

3. **Stockage des rÃ©sultats**  
   ğŸ“Œ Centralisation des donnÃ©es traitÃ©es dans une **base de donnÃ©es PostgreSQL** pour une exploitation future et une visualisation structurÃ©e.

---

## ğŸ—ï¸ PrÃ©sentation de lâ€™Architecture

### ğŸ”¹ Vue GÃ©nÃ©rale
![Vue gÃ©nÃ©rale de l'architecture](img/architecture_simple.png)

### ğŸ”¹ PrÃ©requis
âœ… **Garantir lâ€™ordre de traitement** des calculs dâ€™analyses techniques pour les actions.  
âœ… **RÃ©partition dynamique des partitions** via **Kafka**.

### ğŸ”¹ Gestion des Partitions (Kafka)
![Kafka Partitioning](img/kafka_rep.png)

- **Kafka dÃ©ployÃ© en cluster distribuÃ©** sur plusieurs nÅ“uds pour assurer la **scalabilitÃ© et la tolÃ©rance aux pannes**.
- **Kafka rÃ©partit automatiquement les partitions entre les consommateurs dâ€™un groupe** :
  - ğŸ“Œ Nouveau consommateur â†’ partitions redistribuÃ©es.
  - ğŸ“Œ Consommateur dÃ©faillant â†’ partitions rÃ©assignÃ©es.
  - ğŸ“Œ Une partition = un seul consommateur par groupe â†’ **ordre de traitement garanti**.

### ğŸ”¹ Organisation de l'Architecture
![DÃ©tail du pipeline de traitement](img/architecture_det.png)

ğŸ“Œ **Modules ClÃ©s** :
- **Manager** (Producteur Kafka) â†’ GÃ©nÃ¨re des tÃ¢ches sous forme dâ€™actions contenant le symbole d'une action et une pÃ©riode Ã  traiter. Ces tÃ¢ches sont envoyÃ©es dans un topic Kafka nommÃ© `Stock_topic`, rÃ©parties entre plusieurs partitions pour permettre un **traitement parallÃ¨le et scalable**.
  - ğŸ”¹ **Utilise PostgreSQL (table `symbol_state`)** pour mÃ©moriser la derniÃ¨re date traitÃ©e de chaque symbole afin dâ€™Ã©viter les doublons et faciliter la reprise en cas de panne.

- **Agents** (Producteurs/Consommateurs Kafka) â†’ RÃ©cupÃ¨rent les tÃ¢ches (`Stock_topic`) et utilisent **lâ€™API YFinance** pour collecter les **donnÃ©es journaliÃ¨res** des actions. Ces donnÃ©es sont ensuite envoyÃ©es dans un second topic Kafka nommÃ© `Stock_data_topic`.
  - ğŸ”¹ **Consommateurs appartenant au mÃªme Consumer Group**, permettant une gestion dynamique de la charge.
  - ğŸ”¹ **Assurent la rÃ©partition des tÃ¢ches** entre plusieurs instances pour une scalabilitÃ© optimale.

- **Traiteurs** (Consommateurs Kafka) â†’ RÃ©cupÃ¨rent les **donnÃ©es brutes** depuis `Stock_data_topic` et appliquent des traitements spÃ©cifiques comme le **calcul des indicateurs techniques** (**RSI, MACD, etc.**). Les rÃ©sultats traitÃ©s sont ensuite stockÃ©s dans **PostgreSQL**.
  - ğŸ”¹ **Chaque traiteur traite une partition dÃ©diÃ©e pour garantir lâ€™ordre des calculs**.

### ğŸ”¹ Stockage des DonnÃ©es
La base de donnÃ©es **PostgreSQL** joue un rÃ´le central en tant que **stockage pÃ©renne** des rÃ©sultats traitÃ©s. Elle permet :
- Une organisation structurÃ©e des donnÃ©es.
- Des requÃªtes SQL avancÃ©es pour lâ€™exploitation et lâ€™analyse.

---

## ğŸš€ Technologies UtilisÃ©es

### ğŸ”¹ Langage Principal
- **Python 3** : DÃ©veloppement des microservices avec une riche bibliothÃ¨que pour lâ€™analyse et manipulation de donnÃ©es.

### ğŸ”¹ BibliothÃ¨ques ClÃ©s
- **Pandas** : Manipulation et traitement des donnÃ©es financiÃ¨res via **DataFrames**.
- **Pandas-TA** : Calcul des indicateurs techniques (**RSI, MACD, etc.**).

### ğŸ”¹ AccÃ¨s aux DonnÃ©es
- **YFinance** : API fiable pour rÃ©cupÃ©rer lâ€™historique des valeurs boursiÃ¨res avec des donnÃ©es **structurÃ©es et mises Ã  jour rÃ©guliÃ¨rement**.

### ğŸ”¹ Communication Interservices
- **Confluent-Kafka** :
  - DÃ©ployÃ© en cluster **distribuÃ©** pour assurer **scalabilitÃ©, tolÃ©rance aux pannes et haute disponibilitÃ©**.
  - Gestion efficace des messages dans un environnement distribuÃ©.
  - Assure **dÃ©couplage des services**, **tolÃ©rance aux pannes** et **scalabilitÃ© horizontale**.

### ğŸ”¹ Base de DonnÃ©es
- **PostgreSQL** :
  - Stockage robuste des rÃ©sultats (**donnÃ©es brutes et indicateurs techniques**).
  - Performances optimales pour les **requÃªtes complexes**.

### ğŸ”¹ Conteneurisation et Orchestration
- **Docker** :
  - ExÃ©cution uniforme et **portabilitÃ©** des services sur tous les environnements.
  - Simplification du **dÃ©ploiement et de la maintenance**.
- **Kubernetes** :
  - Orchestration des services pour garantir **scalabilitÃ©** et **haute disponibilitÃ©**.
  - DÃ©ploiement automatisÃ© des **microservices et bases de donnÃ©es**.
  - **Utilisation dâ€™Auto-Scaling avec Keda** pour une gestion dynamique des ressources.

---

## ğŸ”¥ AmÃ©liorations et Optimisations

### ğŸ”¹ Passage Ã  Kubernetes
âœ… **DÃ©ploiement sous un cluster Kubernetes**  
âœ… Migration dâ€™une **configuration locale** vers une **configuration pour Google Cloud Platform (GCP)**

### ğŸ”¹ Auto-Scaling avec Keda
âœ… Configuration dynamique avec un **Ã©quilibreur de charge** pour adapter automatiquement le nombre de services.

### ğŸ”¹ AmÃ©lioration de la RÃ©silience du Manager
âœ… **Stockage de la derniÃ¨re date traitÃ©e** pour chaque symbole afin d'Ã©viter la **crÃ©ation dâ€™actions en double** mÃªme en cas de panne.

---

ğŸ“Œ **Cette architecture garantit la modularitÃ©, la scalabilitÃ© et la fiabilitÃ© nÃ©cessaires pour gÃ©rer efficacement le traitement des donnÃ©es financiÃ¨res Ã  grande Ã©chelle.** ğŸš€